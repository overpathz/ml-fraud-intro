import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import matplotlib.pyplot as plt
import seaborn as sns


def load_data():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–∞–Ω—ñ –∑ —Ñ–∞–π–ª—ñ–≤"""

    # –ß–∏—Ç–∞—î–º–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ñ –∑–∞–ø–∏—Ç–∏
    with open('data/normal_requests.txt', 'r', encoding='utf-8') as f:
        normal_requests = [line.strip() for line in f if line.strip()]

    # –ß–∏—Ç–∞—î–º–æ —Ñ—Ä–æ–¥–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    with open('data/fraud_requests.txt', 'r', encoding='utf-8') as f:
        fraud_requests = [line.strip() for line in f if line.strip()]

    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–∞—Ç–∞—Å–µ—Ç
    data = []
    for req in normal_requests:
        data.append((req, 0))  # 0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π
    for req in fraud_requests:
        data.append((req, 1))  # 1 = —Ñ—Ä–æ–¥

    return data


def extract_features(text):
    """–í–∏—Ç—è–≥—É—î –æ–∑–Ω–∞–∫–∏ –∑ —Ç–µ–∫—Å—Ç—É"""
    text = text.strip()
    text_lower = text.lower()

    # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –∞—Ç–∞–∫
    sql_keywords = ['select', 'drop', 'insert', 'update', 'delete',
                    'union', 'where', 'from', 'table', 'database']

    html_js_patterns = ['script', 'iframe', 'img', 'svg', 'body',
                        'onload', 'onerror', 'alert', 'eval']

    path_patterns = ['../', './', 'etc/', 'windows/', 'system32']

    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ø–∏—Å–æ–∫ –æ–∑–Ω–∞–∫
    features = [
        len(text),  # –¥–æ–≤–∂–∏–Ω–∞ —Ç–µ–∫—Å—Ç—É
        text.count(' '),  # –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–±—ñ–ª—ñ–≤
        text.count("'"),  # –æ–¥–∏–Ω–∞—Ä–Ω—ñ –ª–∞–ø–∫–∏
        text.count('"'),  # –ø–æ–¥–≤—ñ–π–Ω—ñ –ª–∞–ø–∫–∏
        text.count('<'),  # HTML —Ç–µ–≥–∏ –ø–æ—á–∞—Ç–æ–∫
        text.count('>'),  # HTML —Ç–µ–≥–∏ –∫—ñ–Ω–µ—Ü—å
        text.count('='),  # –∑–Ω–∞–∫–∏ —Ä—ñ–≤–Ω–æ—Å—Ç—ñ
        text.count(';'),  # –∫—Ä–∞–ø–∫–∞ –∑ –∫–æ–º–æ—é
        text.count('-'),  # —Ç–∏—Ä–µ
        text.count('('),  # –¥—É–∂–∫–∏
        text.count('/'),  # —Å–ª–µ—à—ñ

        # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –ø—ñ–¥–æ–∑—Ä—ñ–ª–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω—ñ–≤
        sum([1 for word in sql_keywords if word in text_lower]),
        sum([1 for pattern in html_js_patterns if pattern in text_lower]),
        sum([1 for pattern in path_patterns if pattern in text_lower]),
    ]

    return features


def train_and_evaluate():
    """–ù–∞–≤—á–∞—î —Ç–∞ –æ—Ü—ñ–Ω—é—î –º–æ–¥–µ–ª—å"""

    print("üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
    data = load_data()

    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
    texts = [item[0] for item in data]
    labels = [item[1] for item in data]

    print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(texts)} –∑–∞–ø–∏—Å—ñ–≤:")
    print(f"  –ù–æ—Ä–º–∞–ª—å–Ω–∏—Ö: {labels.count(0)}")
    print(f"  –§—Ä–æ–¥–æ–≤–∏—Ö: {labels.count(1)}")

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–∑–Ω–∞–∫
    print("üîß –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–∑–Ω–∞–∫...")
    features = [extract_features(text) for text in texts]
    X = np.array(features)
    y = np.array(labels)

    # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω–∞–≤—á–∞–ª—å–Ω—É —Ç–∞ —Ç–µ—Å—Ç–æ–≤—É –≤–∏–±—ñ—Ä–∫–∏
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"üìã Train: {len(X_train)}, Test: {len(X_test)}")

    # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ Random Forest
    print("ü§ñ –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
    model = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        max_depth=10
    )
    model.fit(X_train, y_train)

    # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    print("üìà –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ...")
    y_pred = model.predict(X_test)

    print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–ò ===")
    print(classification_report(y_test, y_pred,
                                target_names=['Normal', 'Fraud']))

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –º–∞—Ç—Ä–∏—Ü—ñ –ø–æ–º–∏–ª–æ–∫
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Normal', 'Fraud'],
                yticklabels=['Normal', 'Fraud'])
    plt.title('–ú–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫')
    plt.xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ')
    plt.ylabel('–§–∞–∫—Ç–∏—á–Ω–æ')
    plt.savefig('confusion_matrix.png')
    print("üìä –ú–∞—Ç—Ä–∏—Ü—é –ø–æ–º–∏–ª–æ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: confusion_matrix.png")

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
    joblib.dump(model, 'models/fraud_model.joblib')
    print("üíæ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: models/fraud_model.joblib")

    return model


if __name__ == "__main__":
    model = train_and_evaluate()